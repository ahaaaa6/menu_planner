# menu_planner/main.py
import logging
import json
import uuid
import time
import psutil
import hashlib
import asyncio
from contextlib import asynccontextmanager
from concurrent.futures import ProcessPoolExecutor
from typing import List, Union
from fastapi import FastAPI, HTTPException, Body, BackgroundTasks, Path, Request as FastAPIRequest
from .schemas.menu import (
    MenuRequest,
    PlanTaskSubmitResponse,
    MenuResponse,
    MenuPlanCachedResponse,
    PlanResultSuccess,
    PlanResultError,
    PlanResultProcessing,
    PlanResultResponse
)
from .services.menu_fetcher import preprocess_menu
from .services.genetic_planner import plan_menu_async
from .core.cache import redis_manager, RedisConnectionError
from .core.config import settings

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# åº”ç”¨çŠ¶æ€å­˜å‚¨
app_state = {}

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    logger.info("ğŸš€ åº”ç”¨å¯åŠ¨ä¸­...")
    try:
        redis_manager.initialize()
        logger.info("âœ… Redis è¿æ¥æ± åˆå§‹åŒ–æˆåŠŸ")
        ping_result = await redis_manager.ping()
        if ping_result:
            logger.info("âœ… Redis è¿æ¥æµ‹è¯•æˆåŠŸ")
        else:
            logger.warning("âš ï¸ Redis è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œä½†åº”ç”¨å°†ç»§ç»­è¿è¡Œ")
        logger.info(f"ğŸ“¡ Redis é…ç½®: {settings.redis.host}:{settings.redis.port}/{settings.redis.db}")
    except Exception as e:
        logger.error(f"âŒ Redis åˆå§‹åŒ–å¤±è´¥: {e}")

    try:
        app_state["PROCESS_POOL"] = ProcessPoolExecutor(max_workers=settings.process_pool_max_workers)
        logger.info(f"âœ… è¿›ç¨‹æ± å·²åˆ›å»ºï¼Œæœ€å¤§å·¥ä½œè¿›ç¨‹æ•°: {settings.process_pool_max_workers}")
    except Exception as e:
        logger.error(f"âŒ è¿›ç¨‹æ± åˆå§‹åŒ–å¤±è´¥: {e}")
        raise
    
    logger.info("ğŸ‰ åº”ç”¨å·²å‡†å¤‡å°±ç»ª!")
    yield
    
    logger.info("ğŸ›‘ åº”ç”¨å…³é—­ä¸­...")
    if "PROCESS_POOL" in app_state:
        app_state["PROCESS_POOL"].shutdown(wait=True)
        logger.info("âœ… è¿›ç¨‹æ± å·²å…³é—­")
    await redis_manager.close()
    logger.info("âœ… Redis è¿æ¥æ± å·²å…³é—­")


# API æè¿°æ–‡æ¡£
api_description = """
ä¸€ä¸ªå…¨è‡ªåŠ¨çš„é…é¤APIæœåŠ¡ï¼Œèƒ½å¤Ÿæ ¹æ®é¢„ç®—ã€äººæ•°å’Œå®Œæ•´çš„èœå“ä¿¡æ¯ï¼Œåˆ©ç”¨é—ä¼ ç®—æ³•æ¨èå¤šæ ·åŒ–çš„èœå•ç»„åˆã€‚

---

## ğŸš€ API æµ‹è¯•æŒ‡å—

æœ¬APIé‡‡ç”¨**å¼‚æ­¥ä»»åŠ¡**æ¨¡å¼ï¼Œæµ‹è¯•æµç¨‹åˆ†ä¸ºä¸¤æ­¥ï¼š

1.  **æäº¤é…é¤ä»»åŠ¡**:
    - ä½¿ç”¨ `POST /api/v1/plan-menu` ç«¯ç‚¹æäº¤æ‚¨çš„é…é¤éœ€æ±‚ã€‚
    - è¯·æ±‚ä½“ä¸­ **å¿…é¡»** åŒ…å« `diner_count` (å°±é¤äººæ•°), `total_budget` (æ€»é¢„ç®—), ä»¥åŠ `dishes` (ä¸€ä¸ªåŒ…å«æ‰€æœ‰å¯ç”¨èœå“ä¿¡æ¯çš„å®Œæ•´åˆ—è¡¨)ã€‚
    - ç³»ç»ŸéªŒè¯è¯·æ±‚åï¼Œä¼šè¿”å›ä¸€ä¸ª `task_id`ï¼Œä»£è¡¨æ‚¨çš„ä»»åŠ¡å·²è¿›å…¥åå°å¤„ç†é˜Ÿåˆ—ã€‚

2.  **æŸ¥è¯¢é…é¤ç»“æœ**:
    - ä½¿ç”¨ `GET /api/v1/plan-menu/results/{task_id}` ç«¯ç‚¹ï¼Œå¹¶å°†åœ¨ä¸Šä¸€æ­¥ä¸­è·å–çš„ `task_id` ä½œä¸ºè·¯å¾„å‚æ•°ã€‚
    - åå¤è½®è¯¢æ­¤ç«¯ç‚¹ï¼Œç›´åˆ° `status` å˜ä¸º `SUCCESS` æˆ– `FAILED`ã€‚

---

### âš¡ï¸ å…³äºé…é¤æ–¹æ¡ˆç¼“å­˜

ä¸ºäº†é¿å…å¯¹**å®Œå…¨ç›¸åŒçš„è¯·æ±‚**è¿›è¡Œé‡å¤çš„CPUå¯†é›†å‹è®¡ç®—ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€å¥—æ–¹æ¡ˆç¼“å­˜ç³»ç»Ÿã€‚

-   **å·¥ä½œåŸç†**:
    - å½“æ‚¨æäº¤ä»»åŠ¡æ—¶ï¼Œç³»ç»Ÿä¼šæ ¹æ®æ‚¨è¯·æ±‚çš„**æ‰€æœ‰å‚æ•°**ï¼ˆäººæ•°ã€é¢„ç®—å’Œå®Œæ•´çš„èœå“åˆ—è¡¨ï¼‰ç”Ÿæˆä¸€ä¸ªå”¯ä¸€çš„å“ˆå¸Œæ ‡è¯†ã€‚
    - ç³»ç»Ÿä¼šç”¨æ­¤æ ‡è¯†**ä¼˜å…ˆåœ¨ç¼“å­˜ä¸­æŸ¥æ‰¾**æ˜¯å¦å·²æœ‰å®Œå…¨åŒ¹é…çš„ã€è®¡ç®—å¥½çš„èœå•æ–¹æ¡ˆã€‚
    - **å¦‚æœå‘½ä¸­ç¼“å­˜**ï¼ŒAPIå°†**ç«‹å³è¿”å›å®Œæ•´çš„èœå•æ–¹æ¡ˆ**ï¼Œæ•´ä¸ªè¿‡ç¨‹å‡ ä¹æ²¡æœ‰å»¶è¿Ÿï¼Œä¹Ÿä¸ä¼šåˆ›å»ºæ–°çš„åå°ä»»åŠ¡ã€‚
    - **å¦‚æœæœªå‘½ä¸­ç¼“å­˜**ï¼Œç³»ç»Ÿæ‰ä¼šåˆ›å»ºæ–°ä»»åŠ¡ï¼Œå¹¶è¿”å› `task_id` ä¾›æ‚¨åç»­æŸ¥è¯¢ã€‚

-   **å¦‚ä½•æ§åˆ¶ç¼“å­˜**:
    - **`ignore_cache: false` (é»˜è®¤)**: ä¼˜å…ˆä½¿ç”¨ç¼“å­˜ã€‚
    - **`ignore_cache: true`**: å¼ºåˆ¶å¿½ç•¥æ‰€æœ‰ç¼“å­˜ï¼Œæ€»æ˜¯åˆ›å»ºä¸€ä¸ªæ–°çš„åå°ä»»åŠ¡æ¥å®æ—¶è®¡ç®—å…¨æ–°çš„èœå•æ–¹æ¡ˆã€‚

> **æµ‹è¯•å»ºè®®**: åœ¨è¿›è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•æˆ–éœ€è¦ç¡®ä¿è·å¾—å…¨æ–°ç»“æœæ—¶ï¼Œå»ºè®®å°† `ignore_cache` è®¾ç½®ä¸º `true`ã€‚
"""


app = FastAPI(
    title="AIé…é¤æ¨¡å‹ API",
    description=api_description,
    version="1.0.0",
    lifespan=lifespan
)

# --- è¾…åŠ©å‡½æ•°ï¼Œç”¨äºåˆ›å»ºç¼“å­˜é”® ---
def create_plan_cache_key(request: MenuRequest) -> str:
    """ä¸ºæ–¹æ¡ˆè¯·æ±‚åˆ›å»ºä¸€ä¸ªç¡®å®šæ€§çš„ç¼“å­˜é”®"""
    # å¯¹èœå“IDè¿›è¡Œæ’åºï¼Œç¡®ä¿é¡ºåºä¸å½±å“å“ˆå¸Œå€¼
    sorted_dish_ids = sorted([d.dish_id for d in request.dishes])
    key_string = (
        f"{request.diner_count}:{request.total_budget}:"
        f"{','.join(sorted_dish_ids)}"
    )
    return f"plan_cache:{hashlib.md5(key_string.encode()).hexdigest()}"

# --- åå°ä»»åŠ¡æ‰§è¡Œå‡½æ•° ---
async def run_planning_task(request: MenuRequest, task_id: str):
    """
    åå°ä»»åŠ¡æ‰§è¡Œå‡½æ•°ï¼Œå¸¦Redisé‡è¯•é€»è¾‘
    """
    task_result_key = f"task_result:{task_id}"
    plan_cache_key = create_plan_cache_key(request)

    try:
        # 1. ç›´æ¥ä»è¯·æ±‚ä¸­è·å–èœå“å¹¶è¿›è¡Œé¢„å¤„ç†
        all_dishes = request.dishes
        if not all_dishes:
            raise ValueError("è¯·æ±‚ä¸­å¿…é¡»æä¾›èœå“åˆ—è¡¨ã€‚")

        available_dishes, error_msg = preprocess_menu(all_dishes, request)
        if error_msg:
            raise ValueError(error_msg)
        
        logger.info(f"Task {task_id}: ç­›é€‰åå¯ç”¨èœå“æ•°é‡: {len(available_dishes)}")

        # 2. è°ƒç”¨é—ä¼ ç®—æ³•
        menu_results = await plan_menu_async(
            process_pool=app_state["PROCESS_POOL"],
            dishes=available_dishes,
            request=request,
            config=settings
        )
        
        if not menu_results:
            raise ValueError("æŠ±æ­‰ï¼Œæœªèƒ½æ‰¾åˆ°åˆé€‚çš„èœå•æ–¹æ¡ˆï¼Œè¯·æ‚¨ä¿®æ”¹é¢„ç®—æˆ–è°ƒæ•´èœå“åˆ—è¡¨åå†æ¬¡å°è¯•ï¼")

        # 3. æˆåŠŸï¼Œå­˜å‚¨ç»“æœ
        result_data = PlanResultSuccess(
            task_id=task_id,
            status="SUCCESS",
            result=[res.model_dump() for res in menu_results]
        ).model_dump_json()

        # 4. å‡†å¤‡æ–¹æ¡ˆç¼“å­˜æ•°æ®
        cache_data = [res.model_dump() for res in menu_results]
        
        task_saved = await redis_manager.set(task_result_key, result_data, ex=3600)
        cache_saved = await redis_manager.set(
            plan_cache_key,
            json.dumps(cache_data),
            ex=settings.redis.plan_cache_ttl_seconds
        )

        if task_saved:
            logger.info(f"Task {task_id}: æˆåŠŸå®Œæˆå¹¶ä¿å­˜ä»»åŠ¡ç»“æœã€‚")
        else:
            logger.warning(f"Task {task_id}: ä»»åŠ¡å®Œæˆä½†æ— æ³•ä¿å­˜åˆ°Redisã€‚")
        if cache_saved:
            logger.info(f"Task {task_id}: æ–¹æ¡ˆç¼“å­˜å·²æ›´æ–°ï¼Œé”å·²é‡Šæ”¾ã€‚")
        else:
            logger.warning(f"Task {task_id}: æ— æ³•æ›´æ–°æ–¹æ¡ˆç¼“å­˜ã€‚")

    except Exception as e:
        logger.error(f"Task {task_id}: é…é¤ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        error_data = PlanResultError(
            task_id=task_id,
            status="FAILED",
            error=str(e)
        ).model_dump_json()
        
        await redis_manager.set(task_result_key, error_data, ex=3600)
        await redis_manager.delete(plan_cache_key)
        logger.info(f"Task {task_id}: ä»»åŠ¡å¤±è´¥ï¼Œå·²æ¸…ç†æ–¹æ¡ˆç¼“å­˜é”ã€‚Key: {plan_cache_key}")


# --- ä¸»è¦APIç«¯ç‚¹ ---
@app.post("/api/v1/plan-menu", response_model=Union[PlanTaskSubmitResponse, MenuPlanCachedResponse],
    tags=["Menu Planning (Async)"],)
async def submit_menu_plan(
    request: MenuRequest = Body(...),
    background_tasks: BackgroundTasks = BackgroundTasks(),
    fastapi_request: FastAPIRequest = None
):
    """
    æäº¤é…é¤ä»»åŠ¡ï¼ˆå¼‚æ­¥æ¨¡å¼ï¼‰- å¹¶å‘å®‰å…¨ç‰ˆ
    """
    logger.info(f"æ”¶åˆ°é…é¤è¯·æ±‚: äººæ•°={request.diner_count}, é¢„ç®—={request.total_budget}, èœå“æ•°é‡={len(request.dishes)}")

    if request.ignore_cache:
        logger.info("ç”¨æˆ·è¯·æ±‚å¿½ç•¥ç¼“å­˜ã€‚å¼ºåˆ¶åˆ›å»ºæ–°ä»»åŠ¡ã€‚")
        task_id = str(uuid.uuid4())
        task_result_key = f"task_result:{task_id}"
        processing_data = PlanResultProcessing(task_id=task_id, status="PROCESSING").model_dump_json()
        try:
            await redis_manager.set(task_result_key, processing_data, ex=3600)
            background_tasks.add_task(run_planning_task, request, task_id)
            result_url = fastapi_request.url_for('get_menu_plan_result', task_id=task_id)
            return PlanTaskSubmitResponse(task_id=task_id, status="PENDING", result_url=str(result_url))
        except Exception as e:
            logger.error(f"æ— æ³•ä¿å­˜ä»»åŠ¡çŠ¶æ€åˆ°Redis: {e}")
            raise HTTPException(status_code=503, detail="æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚")

    plan_cache_key = create_plan_cache_key(request)

    try:
        cached_value_json = await redis_manager.get(plan_cache_key)
        if cached_value_json:
            cached_data = json.loads(cached_value_json)
            if isinstance(cached_data, list):
                logger.info(f"æ–¹æ¡ˆç¼“å­˜å‘½ä¸­æœ€ç»ˆç»“æœã€‚Key: {plan_cache_key}")
                validated_plans = [MenuResponse(**p) for p in cached_data]
                return MenuPlanCachedResponse(plans=validated_plans)

            if isinstance(cached_data, dict) and cached_data.get("status") == "PROCESSING":
                existing_task_id = cached_data.get("task_id")
                logger.info(f"æ–¹æ¡ˆç¼“å­˜å‘½ä¸­â€œå¤„ç†ä¸­â€æ ‡è®°ï¼Œè¿”å›ç°æœ‰ä»»åŠ¡ID: {existing_task_id}")
                result_url = fastapi_request.url_for('get_menu_plan_result', task_id=existing_task_id)
                return PlanTaskSubmitResponse(task_id=existing_task_id, status="PENDING", result_url=str(result_url))

            logger.warning(f"ç¼“å­˜æ•°æ®æ ¼å¼ä¸æ­£ç¡®ï¼Œåˆ é™¤æŸåçš„ç¼“å­˜ã€‚Key: {plan_cache_key}")
            await redis_manager.delete(plan_cache_key)
            
    except (RedisConnectionError, json.JSONDecodeError, TypeError, ValueError) as e:
        logger.warning(f"æ£€æŸ¥ç¼“å­˜æ—¶å‘ç”Ÿé”™è¯¯æˆ–æ ¼å¼ä¸åŒ¹é…ï¼Œå°†ç»§ç»­å°è¯•åˆ›å»ºä»»åŠ¡: {e}")
        pass

    task_id = str(uuid.uuid4())
    processing_marker = PlanResultProcessing(task_id=task_id, status="PROCESSING").model_dump_json()

    try:
        lock_acquired = await redis_manager.set(
            plan_cache_key,
            processing_marker,
            ex=600,
            nx=True
        )

        if lock_acquired:
            logger.info(f"æˆåŠŸè·å–åˆ†å¸ƒå¼é”ã€‚åˆ›å»ºæ–°ä»»åŠ¡: {task_id} for key: {plan_cache_key}")
            task_result_key = f"task_result:{task_id}"
            await redis_manager.set(task_result_key, processing_marker, ex=3600)
            background_tasks.add_task(run_planning_task, request, task_id)
            result_url = fastapi_request.url_for('get_menu_plan_result', task_id=task_id)
            return PlanTaskSubmitResponse(task_id=task_id, status="PENDING", result_url=str(result_url))
        else:
            logger.info(f"è·å–é”å¤±è´¥ï¼Œå¦ä¸€è¿›ç¨‹å·²æŠ¢å…ˆã€‚ç­‰å¾…å¹¶è¯»å–ç°æœ‰ä»»åŠ¡ID...")
            await asyncio.sleep(0.1)
            
            existing_marker_json = await redis_manager.get(plan_cache_key)
            if existing_marker_json:
                try:
                    existing_marker = json.loads(existing_marker_json)
                    if isinstance(existing_marker, dict) and existing_marker.get("status") == "PROCESSING":
                        existing_task_id = existing_marker.get("task_id")
                        logger.info(f"æˆåŠŸè¯»å–åˆ°ç°æœ‰ä»»åŠ¡ID: {existing_task_id}")
                        result_url = fastapi_request.url_for('get_menu_plan_result', task_id=existing_task_id)
                        return PlanTaskSubmitResponse(task_id=existing_task_id, status="PENDING", result_url=str(result_url))
                except (json.JSONDecodeError, TypeError, ValueError):
                    pass

            logger.error(f"é”çŠ¶æ€ä¸¥é‡ä¸ä¸€è‡´ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿã€‚Key: {plan_cache_key}")
            raise HTTPException(status_code=409, detail="è¯·æ±‚å†²çªï¼Œè¯·ç¨åé‡è¯•ã€‚")

    except RedisConnectionError as e:
        logger.error(f"å¤„ç†åˆ†å¸ƒå¼é”æ—¶Rediså‡ºé”™: {e}", exc_info=True)
        raise HTTPException(status_code=503, detail="æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚")
    except Exception as e:
        logger.error(f"åˆ›å»ºä»»åŠ¡æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ã€‚")


@app.get("/api/v1/plan-menu/results/{task_id}", response_model=PlanResultResponse, tags=["Menu Planning (Async)"])
async def get_menu_plan_result(task_id: str = Path(..., description="æäº¤ä»»åŠ¡æ—¶è·å–çš„Task ID")):
    """
    æ ¹æ®ä»»åŠ¡IDæŸ¥è¯¢é…é¤ç»“æœï¼Œå¸¦é‡è¯•é€»è¾‘
    """
    task_result_key = f"task_result:{task_id}"
    
    try:
        result_json = await redis_manager.get(task_result_key)
        
        if not result_json:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡IDä¸å­˜åœ¨æˆ–å·²è¿‡æœŸã€‚")
        
        result_data = json.loads(result_json)
        return result_data
        
    except RedisConnectionError:
        raise HTTPException(status_code=503, detail="RedisæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚")
    except json.JSONDecodeError:
        raise HTTPException(status_code=500, detail="ä»»åŠ¡ç»“æœæ•°æ®æŸåã€‚")

@app.get("/health", tags=["Health Check"])
async def health_check():
    redis_status = await redis_manager.get_connection_status()
    redis_ping = await redis_manager.ping()
    return {
        "status": "ok" if redis_ping else "degraded",
        "message": "æ¬¢è¿ä½¿ç”¨AIé…é¤æ¨¡å‹ API v1.0",
        "redis": {
            "connected": redis_ping,
            "status": redis_status
        },
        "timestamp": time.time()
    }

@app.get("/api/v1/redis/status", tags=["Health Check"])
async def redis_status():
    status = await redis_manager.get_connection_status()
    ping_result = await redis_manager.ping()
    return {
        "connection_status": status,
        "ping_successful": ping_result,
        "timestamp": time.time()
    }

@app.get("/", tags=["Health Check"])
def read_root():
    return {"status": "ok", "message": "æ¬¢è¿ä½¿ç”¨AIé…é¤æ¨¡å‹ API v1.0"}